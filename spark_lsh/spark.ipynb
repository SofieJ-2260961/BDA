{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a87a1-b79d-487a-854e-80af69e90606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark configuration\n",
    "import os \n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=3g  pyspark-shell\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "JAVA_HOME = \"/usr/lib/jvm/java-1.17.0-openjdk-amd64\" # Set Java version (>=17)\n",
    "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
    "\n",
    "try: \n",
    "    spark\n",
    "    print(\"Spark application already started. Terminating existing application and starting new one\")\n",
    "    spark.stop()\n",
    "except: \n",
    "    pass\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"demoRDD\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "sc=spark.sparkContext\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input data from file and convert it to key-value pairs, \n",
    "# with the post id as key and a list of shingles as value.\n",
    "# The data should be structured as a post id and the (unhashed) shingles per line.\n",
    "# Use convert_xml.py to get this structure.\n",
    "\n",
    "input_data = \"data/se_parsed.txt\"\n",
    "unhashed_shingles = (sc.textFile(input_data)\n",
    "         .map(lambda line: line.split(\",\"))\n",
    "         .map(lambda x: (int(x[0]), x[1:]))\n",
    "         .filter(lambda kv: len(kv[1]) > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import hashlib\n",
    "\n",
    "def str_to_int32(s):\n",
    "    return int.from_bytes(hashlib.sha1(s.encode(\"utf-8\")).digest()[:4], \"little\")\n",
    "\n",
    "a1 = random.randint(0, 2**32)\n",
    "b1 = random.randint(0, 2**32)\n",
    "p = 2**61 - 1 # Mersenne prime \n",
    "\n",
    "def hash_shingle(s) -> int:\n",
    "    x = str_to_int32(s) \n",
    "    hash = ((a1*x + b1) % p) % 2**32\n",
    "    return hash\n",
    "\n",
    "def hash_post(shingles) -> list[int]:\n",
    "    hashed = []\n",
    "    for shingle in shingles:\n",
    "        hashed.append(hash_shingle(shingle))\n",
    "    return hashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_shingles = unhashed_shingles.map(lambda kv: (kv[0], hash_post(kv[1]))).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinHash parameters\n",
    "num_minhashes = 45  # number of hash functions in the MinHash signature\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "max_uint32 = 2**32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b18eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate parameters (a and b) for k hash functions\n",
    "hash_params = [(random.randint(1, max_uint32-1), random.randint(0, max_uint32-1)) for _ in range(num_minhashes)]\n",
    "hash_params_bc = sc.broadcast(hash_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minhash(shingle_hashes):\n",
    "    if not shingle_hashes:\n",
    "        return [-1]*len(hash_params)\n",
    "    sig = []\n",
    "    for a,b in hash_params:\n",
    "        m = min((((a*i + b) % p) % 2**32) for i in shingle_hashes)\n",
    "        sig.append(m)\n",
    "    return sig\n",
    "\n",
    "minhash_sigs = hashed_shingles.mapValues(lambda hashes: create_minhash(hashes)).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSH parameters\n",
    "t = 0.4\n",
    "rows_per_band = 3\n",
    "bands = 15\n",
    "\n",
    "# Check that rows * bands is equal to the number of MinHashes\n",
    "assert rows_per_band * bands == num_minhashes, f\"rows * bands = {rows_per_band * bands} != minhash_rows = {num_minhashes}\"\n",
    "print(f\"t = {t}, (1/b)^(1/r) = {(1 / bands) ** (1 / rows_per_band)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book on LSH:\n",
    "# \"For each band, there is a hash function that takes vectors of r integers\n",
    "# (the portion of one column within that band) and hashes them to some large\n",
    "# number of buckets. We can use the same hash function for all the bands, but\n",
    "# we use a separate bucket array for each band, so columns with the same vector\n",
    "# in different bands will not hash to the same bucket.\"\"\n",
    "\n",
    "def lsh_bucket_pairs(post_id, sig):\n",
    "    # produce ((band, bucket_hash), post_id) for each band\n",
    "    for band in range(bands):\n",
    "        start = band * rows_per_band\n",
    "        end = start + rows_per_band\n",
    "        sig_slice = sig[start:end] \n",
    "\n",
    "        x = 0\n",
    "        for r, v in enumerate(sig_slice):\n",
    "            # x += r * v\n",
    "            x = ((x * 1000003) ^ (v + 0x9e3779b9 + (r << 6) + (r >> 2))) & 0xFFFFFFFF\n",
    "        bucket_hash = ((a1 * x + b1) % p) % 2**32\n",
    "        yield ((band, bucket_hash), post_id)\n",
    "\n",
    "# create RDD of ((band, bucket), [post_ids]) \n",
    "buckets_rdd = (\n",
    "    minhash_sigs\n",
    "    .flatMap(lambda kv: lsh_bucket_pairs(kv[0], kv[1]))\n",
    "    .map(lambda kv: (kv[0], [kv[1]]))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    ")\n",
    "\n",
    "# Keep only buckets with more than one post \n",
    "candidate_buckets = buckets_rdd.filter(lambda kv: len(kv[1]) > 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88659d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "pair_counts = (\n",
    "    candidate_buckets\n",
    "    .flatMap(lambda kv: [tuple(sorted((i, j))) for i, j in combinations(kv[1], 2)])\n",
    "    .map(lambda pair: (pair, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes several minutes to compute \n",
    "top_pairs = pair_counts.map(lambda kv: (kv[1], kv[0])).sortByKey(False).take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the number of buckets a pair was found in,\n",
    "# vs the true Jaccard similarity and MinHash similarity\n",
    "\n",
    "needed_ids = {i for _, (i, j) in top_pairs for i in (i, j)}\n",
    "hs_map = hashed_shingles.filter(lambda kv: kv[0] in needed_ids).collectAsMap()\n",
    "ms_map = minhash_sigs.filter(lambda kv: kv[0] in needed_ids).collectAsMap()\n",
    "\n",
    "for count, (i, j) in top_pairs:\n",
    "    shingles_i = set(hs_map.get(i, []))\n",
    "    shingles_j = set(hs_map.get(j, []))\n",
    "\n",
    "    sigs_i = ms_map.get(i)\n",
    "    sigs_j = ms_map.get(j)\n",
    "\n",
    "    if len(shingles_i) == 0 and len(shingles_j) == 0:\n",
    "        true_jaccard = 1.0\n",
    "    elif len(shingles_i) == 0 or len(shingles_j) == 0:\n",
    "        true_jaccard = 0.0\n",
    "    else:\n",
    "        true_jaccard = len(shingles_i & shingles_j) / len(shingles_i | shingles_j)\n",
    "\n",
    "    if sigs_i is None or sigs_j is None:\n",
    "        minhash_sim = None\n",
    "    else:\n",
    "        minhash_sim = sum(1 for a, b in zip(sigs_i, sigs_j) if a == b) / len(sigs_i)\n",
    "\n",
    "    print(f\"{(i, j)}: {count}, jaccard similarity: {true_jaccard:.3f}, minhash similarity: {minhash_sim:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d41a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
