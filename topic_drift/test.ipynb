{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "54c64267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/diana/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/diana/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/diana/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import scipy\n",
    "import ast\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab') # Maybe not needed?\n",
    "\n",
    "# TODO:\n",
    "    # [ ] Preprocessing\n",
    "    # [ ] Unieke woorden tellen\n",
    "    # [ ] TF*IDF\n",
    "    # [ ] Clusteren\n",
    "    # [ ] Bekijk topic per cluster\n",
    "    # [ ] Visualiseer evolutie  over tijd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0679a661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_type</th>\n",
       "      <th>booktitle</th>\n",
       "      <th>journal</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>SDM</td>\n",
       "      <td></td>\n",
       "      <td>2019</td>\n",
       "      <td>Feature selection as Monte-Carlo Search in Gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>SDM</td>\n",
       "      <td></td>\n",
       "      <td>2002</td>\n",
       "      <td>Mining Relationship between Triggering and Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>SDM</td>\n",
       "      <td></td>\n",
       "      <td>2007</td>\n",
       "      <td>Segmentations with Rearrangements.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>SDM</td>\n",
       "      <td></td>\n",
       "      <td>2021</td>\n",
       "      <td>MT-STNets: Multi-Task Spatial-Temporal Network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>SDM</td>\n",
       "      <td></td>\n",
       "      <td>2006</td>\n",
       "      <td>A Semantic Approach for Mining Hidden Links fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14480</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>KDD</td>\n",
       "      <td></td>\n",
       "      <td>1996</td>\n",
       "      <td>Using a Hybrid Neural/Expert System for Data B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14481</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>KDD</td>\n",
       "      <td></td>\n",
       "      <td>2021</td>\n",
       "      <td>Table2Charts: Recommending Charts by Learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14482</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>KDD</td>\n",
       "      <td></td>\n",
       "      <td>2021</td>\n",
       "      <td>Physical Equation Discovery Using Physics-Cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14483</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>KDD</td>\n",
       "      <td></td>\n",
       "      <td>2023</td>\n",
       "      <td>Accelerating Personalized PageRank Vector Comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14484</th>\n",
       "      <td>inproceedings</td>\n",
       "      <td>KDD</td>\n",
       "      <td></td>\n",
       "      <td>2019</td>\n",
       "      <td>A Memory-Efficient Sketch Method for Estimatin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14485 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      publication_type booktitle journal  year  \\\n",
       "0        inproceedings       SDM          2019   \n",
       "1        inproceedings       SDM          2002   \n",
       "2        inproceedings       SDM          2007   \n",
       "3        inproceedings       SDM          2021   \n",
       "4        inproceedings       SDM          2006   \n",
       "...                ...       ...     ...   ...   \n",
       "14480    inproceedings       KDD          1996   \n",
       "14481    inproceedings       KDD          2021   \n",
       "14482    inproceedings       KDD          2021   \n",
       "14483    inproceedings       KDD          2023   \n",
       "14484    inproceedings       KDD          2019   \n",
       "\n",
       "                                                   title  \n",
       "0      Feature selection as Monte-Carlo Search in Gro...  \n",
       "1      Mining Relationship between Triggering and Con...  \n",
       "2                     Segmentations with Rearrangements.  \n",
       "3      MT-STNets: Multi-Task Spatial-Temporal Network...  \n",
       "4      A Semantic Approach for Mining Hidden Links fr...  \n",
       "...                                                  ...  \n",
       "14480  Using a Hybrid Neural/Expert System for Data B...  \n",
       "14481  Table2Charts: Recommending Charts by Learning ...  \n",
       "14482  Physical Equation Discovery Using Physics-Cons...  \n",
       "14483  Accelerating Personalized PageRank Vector Comp...  \n",
       "14484  A Memory-Efficient Sketch Method for Estimatin...  \n",
       "\n",
       "[14485 rows x 5 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read input file and create table\n",
    "records = []\n",
    "with open(\"data/data_mining_publications.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            records.append(ast.literal_eval(line))\n",
    "\n",
    "\n",
    "table = pd.DataFrame(records)\n",
    "\n",
    "# Get all titles\n",
    "titles = table['title'].to_list()\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5fbd9e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 97786, unique words: 9669\n"
     ]
    }
   ],
   "source": [
    "# Initialize stemmer\n",
    "ps: PorterStemmer = PorterStemmer()\n",
    "\n",
    "# Other option (below): lemmatization\n",
    "# This returns valid words, but can only be done on one type (eg. nouns or verbs), \n",
    "# so others will still create duplicates\n",
    "\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"omw-1.4\")\n",
    "# wnl = WordNetLemmatizer()\n",
    "\n",
    "# Get English stop words and punctuation dict\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "\n",
    "filtered_titles: list[list[str]] = []\n",
    "unique_word_counts: defaultdict[str, int] = defaultdict(int)\n",
    "total_words: int = 0\n",
    "\n",
    "for title in titles:\n",
    "    # Set string to lowercase and remove punctuation\n",
    "    title_words = word_tokenize(title.lower().translate(punct))\n",
    "\n",
    "    # Remove stopwords and stem each word\n",
    "    filtered_title = [ps.stem(word) for word in title_words if word not in stop_words]\n",
    "    # filtered_title = [wnl.lemmatize(word, pos=\"v\") for word in title_words if word not in stop_words]\n",
    "    # filtered_title = [word for word in title_words if word not in stop_words]\n",
    "    filtered_titles.append(filtered_title)\n",
    "    total_words += len(filtered_title)\n",
    "    \n",
    "    for word in filtered_title:\n",
    "        unique_word_counts[word] += 1\n",
    "\n",
    "\n",
    "print(f\"Total words: {total_words}, unique words: {len(unique_word_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n docs, vocab size: (14485, 9667)\n"
     ]
    }
   ],
   "source": [
    "# This part creates a TF*IDF matrix (can be used for clustering later on!)\n",
    "tfidf_titles = [\" \".join(tokens) for tokens in filtered_titles]\n",
    "\n",
    "vec = TfidfVectorizer(lowercase=False,  # we already lowercased/stemmed tokens\n",
    "                      token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "                      smooth_idf=True,  # add 1 to numerator/denominator (stability)\n",
    "                      use_idf=True)\n",
    "\n",
    "tfidf_matrix = vec.fit_transform(tfidf_titles)\n",
    "vocab = vec.get_feature_names_out()\n",
    "# print(\"n docs, vocab size:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea871c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf 0.3827972514282151\n",
      "acycl 0.3671000211130385\n",
      "montecarlo 0.35596265896147644\n",
      "grow 0.3204892572648419\n",
      "root 0.31033205211090426\n",
      "singl 0.2882439023061207\n",
      "best 0.2834974596441657\n",
      "direct 0.24406442093090747\n",
      "identif 0.23718564811915677\n",
      "search 0.18717256659593434\n"
     ]
    }
   ],
   "source": [
    "# Test TF*IDF matrix\n",
    "i = 0\n",
    "row = tfidf_matrix.getrow(i)\n",
    "indices = row.indices\n",
    "data = row.data\n",
    "top_n = 10\n",
    "order = data.argsort()[::-1][:top_n]\n",
    "for pos in order:\n",
    "    print(vocab[indices[pos]], data[pos])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
